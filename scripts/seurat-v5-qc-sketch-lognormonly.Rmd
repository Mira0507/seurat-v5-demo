---
title: "scRNA-seq QC"
output:
    html_document:
        code_folding: hide
        toc: true
        toc_float: true
        toc_depth: 3
        df_print: paged
---

```{r}
knitr::opts_chunk$set(
    warning=FALSE,
    message=FALSE,
    cache.lazy=FALSE)
```

```{r libraries}
library(Seurat)
library(BPCells)
library(scDblFinder)
library(tidyverse)
library(patchwork)
library(future)
library(parallel)
library(BiocParallel)
library(Matrix)
library(DT)
library(UpSetR)

source('../helpers.R')
```

```{r future_parallelization}

# ------------------------------------------------------------------------------
# Set up parallel computing
# ------------------------------------------------------------------------------

# Assign the number of cores for parallelization
ncpus <- future::availableCores()

# Adjust max memory allowed
options(future.globals.maxSize=500000 * 1024^2,   # 500G (1000 * 1024^2 = 1G)
        mc.cores=ncpus,
        MulticoreParam=quote(MulticoreParam(workers=ncpus)),
        future.rng.onMisuse="ignore")

# Parallelize the run
plan("multicore", workers=ncpus)

register(MulticoreParam(workers=ncpus))
```

# Overview

This document details the QC stages of scRNA-seq analysis and runs PCA and UMAP on 
both the integrated and non-integrated data after SCTransform normalization.

The final SeuratObject is saved at the end, which can be loaded into downstream 
clustering and marker gene identification analyses, which happen in other documents.
This lets us prepare the data just once here and then try out multiple parameters 
downstream independently.

```{r config, cache=TRUE}

# ------------------------------------------------------------------------------
# User configuration:
# - input/output files and directories
# - user variables
# ------------------------------------------------------------------------------

# Assign file path to sampletable
sampletable <- '../sampletable.tsv'
sample_paths <- get_sample_paths(sampletable)

# Assign factor levels
age.levels <- c(
    '6w',
    '10w',
    '12w',
    '14w',
    '18w')

genotype.levels <- c('WT', 'cKO')
sex.levels <- c('M', 'F')


# Assign metric names associated with scDblFinder
doublet_class <- 'scDblFinder.class'
doublet_score <- 'scDblFinder.score'

# Set regex patterns to detect mitochondrial/ribosomal genes. This may need to be
# tweaked based on the species being analyzed.
#
# mito_pattern matches 'mt-**', 'Mt_**', 'MT-**', 'mt:**'
# ribo_pattern matches 'Rps**', 'Rpl**', 'RPS**', 'RPL**', etc
mito_pattern <- '^mt-|Mt_|MT-|mt:'
ribo_pattern <- '^R[p|P][s|S]*[l|L]*'

# Set qc metrics to calculate
qc_metrics <- c('nFeature_RNA', 'nCount_RNA', 'percent.mito')

# Which qc metrics to plot
plot_metrics <- c('percent.mito', 'percent.ribo',
                  'nFeature_RNA', 'nCount_RNA')

# Set number of variable features for performing SCTransform
variable.features.n <- 3000

# Pick assay to use for integration
selected_assay <- 'RNA'

# Decide whether not to run SCTransform v2
sct.v2 <- TRUE

# Dimension reduction assays
# By default, this only contains the assay selected above
dimred_assays <- selected_assay

# Set max number of PCs to calculate. Used in RunPCA()
pca_dims <- 60

# Set number of UMAP dimensions to calculate. Used in RunUMAP()
umap_dims <- 40

pref <- 'seurat-v5-qc-sketch'


# Create a subdirectory to store BPCells matices 
bpc.dir <- paste0(pref, '-BPCells')
if (!dir.exists(bpc.dir)) {
    # Create a new one if there's no pre-existing directory
    dir.create(bpc.dir)
} else {
    # Remove and create a new one if there's already pre-existing directory
    # NOTE: this is required due to errors raised by `wirte_matrix_dir`
    #       when finding a directory with the same name
    unlink(bpc.dir, recursive=TRUE)
    dir.create(bpc.dir)
}


# Determine whether you'll run integration on sketched data
# NOTE: Set to TRUE if your input has more than 2^31-1
sketch.dataset <- TRUE
```

# Read data

Data are imported from the output directories created by 10X Genomicsâ€™ Cell Ranger 
into a list of Seurat objects, one per sample.

```{r read_data, cache=TRUE, dependson='config'}

# ------------------------------------------------------------------------------
# Cellragner-generated `h5` files are imported and saved as BPCells 
# matrices on disk
# 
# See https://satijalab.org/seurat/articles/seurat5_bpcells_interaction_vignette#load-data-from-one-h5-file
# ------------------------------------------------------------------------------

# Read and create a list of seurat obj
obj.list <- mclapply(names(sample_paths), function(name) {

    # Create a seurat obj with in-memory dgCMatrix
    path <- sample_paths[name]
    sc.data <- Read10X(path)
    obj <- CreateSeuratObject(sc.data)

    # Write the matrix on-disk
    # (Overwrites pre-existing matrix!)
    ondisk.path <- file.path(bpc.dir, name)
    if (dir.exists(ondisk.path)) {
        unlink(ondisk.path, recursive=TRUE)
    }
    write_matrix_dir(mat=obj[['RNA']]$counts, dir=ondisk.path)

    # Replace the count matrix with on-disk `BPCells` matrix
    obj.mat <- open_matrix_dir(ondisk.path)
    obj[['RNA']]$counts <- obj.mat

    # Update the `orig.ident` column in the metadata to samplename
    obj$orig.ident <- name

    # Add metadata columns and convert each column to `factor if necessary
    obj@meta.data <- obj@meta.data %>%
        separate(orig.ident,
            c('age', 'genotype', 'sex', 'rep'),
            remove=FALSE) %>%
        mutate(genotype=factor(genotype, levels=genotype.levels),
            sex=factor(sex, levels=sex.levels),
            age=factor(age, levels=age.levels),
            orig.ident=factor(orig.ident, levels=names(sample_paths))
        )
    return(obj)
    }
) %>%
    set_names(names(sample_paths))

```

# QC

This section shows the various calculated QC metrics and thresholds.


## Cliff-knee plot {.tabset}

Here we show a plot of UMI counts vs barcodes, also known as the `cliff-knee`
plot, for each sample.

- The color of the line indicates whether a particular barcode
  was classified by `cellranger` as coming from an actual cell
  (`black`) or was part of the background (`gray`).
- The cells colored in `black` form the starting point of our
  analysis workflow.

```{r cliff_knee, results='asis', cache=TRUE, dependson='read_data'}

# ------------------------------------------------------------------------------
#
# Create Cliss-knee plots
#
# ------------------------------------------------------------------------------

p_list <- mclapply(sample_paths, get_cliff_knee) %>%
    set_names(names(obj.list))

for(s in names(p_list)){
    mdcat(s, level=3)
    print(p_list[[s]])
    cat('\n\n')
}

```

## Doublet detection

Doublets are detected using the `scDblFinder` package. This finds possible
doublets missed by Cell Ranger's cliff-knee plots; these will be filtered out.

```{r doubletfinding, dependson='read_data', cache=TRUE}

# -------------------------------------------------------------------------------
# Use scDblFinder package to identify doublets. This is done on the raw counts,
# and for each sample separately. We need to temporarily convert to SCE for the
# purposes of doublet detection. The resulting SeuratObj has additional columns:
#
# - scDblFinder.class
# - scDblFinder.score
# - scDblFinder.weighted
# - scDblFinder.cxds_score
# ------------------------------------------------------------------------------


# NOTE:
# - The `BPCells` matrix is not compatible with `sce`.
# - We conver the count layer with an on-disk `BPCells` matrix to an in-memory `dgCMatrix`.
obj.list <- mclapply(names(obj.list), function(name) {

    # Converts on-disk BPCells matrix to in-memory dgCMatrix in each seurat obj
    x <- obj.list[[name]]
    counts <- as(object=x[['RNA']]$counts, Class='dgCMatrix')
    x[['RNA']]$counts <- counts

    # Convert seurat obj to sce obj
    sce <- as.SingleCellExperiment(x)

    # Compute doublets
    sce <- scDblFinder(sce)

    # Slice columns created by scDblFinder in the `colData`
    dbl.df <- colData(sce) %>%
        as.data.frame() %>%
        dplyr::select(starts_with('scDblFinder'))

    # Add the new columns to the seurat j
    x@meta.data <- cbind(x@meta.data, dbl.df)

    # Convert in-memory `dgCMatrix` to on-disk `BPCells` matrix
    ondisk.path <- file.path(bpc.dir, name)
    obj.mat <- open_matrix_dir(ondisk.path)
    x[['RNA']]$counts <- obj.mat

    return(x)
    }
) %>%
    set_names(names(obj.list))
```

```{r print_doublets}
data.frame(
    count=sapply(obj.list, function(x) sum(x$scDblFinder.class=='doublet')),
    total=sapply(obj.list, function(x) ncol(x))
) %>%
    mutate(percent=round(count/total*100, 2)) %>%
    dplyr::select(-total) %>%
    knitr::kable()
```


## Quality metrics {.tabset}

Here we use the `scuttle::isOutlier()` function on various metrics. This
automatically selects a threshold, flagging cells that exceed 3 median absolute
deviations. This avoids qualitative, *ad hoc* filtering choices, and lets use
thresholds in a dataset-specific manner.

Note that in cases where the lower value is negative and the metrics only take
positive values, there will not be a negative threshold.

The table shows the values; the plot shows horizontal lines for each threshold
for each sample. Only metrics listed in the table (and those that have
horizontal lines) are used for filtering purposes.

```{r thresholds, results='asis', dependson='doubletfinding', cache=TRUE}
# ------------------------------------------------------------------------------
# - Calculate the percentage of mitochondrial and ribosomal gene expression
# - Update metadata with columns indicating outlier cells to be removed
# ------------------------------------------------------------------------------

obj.list <- lapply(obj.list,
    function(x) add_percentage_features(
        x,
        mito_pattern=mito_pattern,
        ribo_pattern=ribo_pattern,
        mito_label='percent.mito',
        ribo_label='percent.ribo')
)

# TODO: add check to see if all percent.mito/percent.ribo == 0

# Use isOutlier() to detect cells with MAD > 3 and store in data.frame `m`.

# NOTE: recall that in purrr parlance, _dfr suffix means "glue together the
# returned dataframes, row-wise". imap provides both the object and the name
# (as opposed to just the object for map) which allows us to properly add the
# orig.id column.
m <- do.call('rbind',
    lapply(names(obj.list),
           function(x) find_thresholds(obj.list[[x]], x, metrics=qc_metrics)
    )
)

metrics_df <- purrr::map_dfr(obj.list, function (x) x@meta.data) %>%
  dplyr::select(all_of(plot_metrics), orig.ident) %>%
  reshape2::melt()


m2 <- m %>%
    rename(orig.ident=orig.id, variable=metric)

# Apply thresholds based on `m`
for (ident in unique(m$orig.id)){
   mdata <- obj.list[[ident]]@meta.data

   mdata$any_outlier <- FALSE
   for (metric.i in unique(m$metric)){
     s <- dplyr::filter(m, orig.id==ident, metric==metric.i)
     above <- mdata[, metric.i] > s$higher
     mdata[, paste0(metric.i, '_outlier')] <- above
     mdata$any_outlier <- mdata$any_outlier | above
   }

   # We also want to remove doublets.
   mdata$keep <- !(mdata$any_outlier | mdata[, doublet_class ] == 'doublet')

   obj.list[[ident]]@meta.data <- mdata
}
```

```{r display_qc_thres, results='asis'}

# ------------------------------------------------------------------------------
# Clean and display QC results
# ------------------------------------------------------------------------------

# reformat table of QC metric thresholds
m_new <- list()
for(i in 1:nrow(m)){
    s <- m[i, 'orig.id']
    tmp <- setNames(m[i, c('lower', 'higher')],
                    paste0(m[i, 'metric'], '_', c('lower','higher')))
    if(!s %in% names(m_new)){
      m_new[[s]] <- tmp
    } else {
      m_new[[s]] <- c(m_new[[s]], tmp)
    }
}

m_new_df <- as.data.frame(do.call('rbind', m_new))
m_new_df <- cbind(sample=rownames(m_new_df), m_new_df)

# build sketch to show thresholds
sketch <- htmltools::withTags(table(
    class = 'display',
    thead(
        tr(
            th(rowspan=2, 'sample'),
            lapply(qc_metrics,
                   function(x) th(class='dt-center', colspan=2, x))
        ),
        tr(
            lapply(rep(c('lower','higher'), length(qc_metrics)), th)
        )
    )
))

# display table using sketch

# NOTE:
#
# - columnDefs uses 0-based column indexing
# - formatSignif uses 1-based column indexing
mdcat('Table', level=3)
m_new_df %>%
    datatable(rownames=FALSE,
        container=sketch,
        options=list(
            columnDefs=list(list(className='dt-center',
                                 targets=1:(ncol(m_new_df)-1))))
        ) %>%
    formatSignif(columns=2:ncol(m_new_df),
                 digits=4)
cat('\n\n')
```


```{r qc_metric_plot, results='asis', fig.width=10, fig.height=8}

# ------------------------------------------------------------------------------
# Plot QC results
# ------------------------------------------------------------------------------


# plot metric thresholds
metrics_df <- metrics_df %>%
    mutate(orig.ident=factor(orig.ident, levels=names(obj.list)))
mdcat('Plot {.tabset}', level=3)
for (var in unique(metrics_df$variable)) {
    mdcat(var, level=4)
    p <- ggplot(metrics_df %>% dplyr::filter(variable == var)) +
      aes(y=value, x=orig.ident, fill=orig.ident) +
      theme(axis.text.x=element_text(angle=90, vjust=0.1, hjust=1)) +
      geom_violin() +
      geom_hline(data=m2[m2$variable == var,],
                 aes(yintercept=higher, color=orig.ident))

    print(p)
}


```

## UpSet plots of filtered cells {.tabset}

Here we show the distribution of cells that were filtered out due to possibly
multiple metrics.

```{r upset_plot, results='asis'}

# ------------------------------------------------------------------------------
# Plot outlier cells being unique and intersecting across the QC metrics
# ------------------------------------------------------------------------------

# UpSet plots of filtered cells
filtered_matrix <- list()
for (name in names(obj.list)){
    mdcat(name, '{.tabset}', level=3)
    metric_cols <- sapply(qc_metrics, function(x) paste0(x, '_outlier'))

    mdata <- obj.list[[name]]@meta.data
    filtered_matrix[[name]] <- cbind(
        mdata[, metric_cols],
        doublet=mdata[, doublet_class] == 'doublet')

    print(upset(filtered_matrix[[name]] + 0,
                text.scale=1.5))
}
```

## Filtering summary

Here we summarize the number of cells that were filtered out
based on quality metrics and doublet detection.

```{r filtering_summary}
# ------------------------------------------------------------------------------
# Print QC summary table
# ------------------------------------------------------------------------------

filt <- lapply(names(obj.list), function(x){
    mdata <- obj.list[[x]]@meta.data
    raw <- nrow(mdata)
    ff <- colSums(filtered_matrix[[x]])
    filtered <- sum(mdata[, 'keep'])
    c(raw=raw,
      ff,
      filtered=filtered,
      filtered.pct=(raw - filtered)/raw)
})
df <- do.call('rbind', filt)
df <- cbind(sample=names(obj.list), df)
knitr::kable(df)

```

```{r save_qc, eval=FALSE}
qc_list <- list(
    metadata=lapply(obj.list, function(x) x@meta.data),
    thresholds=m %>% rename(orig.ident=orig.id))
saveRDS(qc_list, paste0(pref, '-qc.Rds'))
```

# Normalization

We normalize single cells by dividing feature counts per cell by the total counts for that cell, followed by
multiplication with the `scale.factor`, and then transforming to the natural log scale using `log1p`.


```{r sctransform_option}
print(
    paste0('Calling LogNormalize...')
    )
```


```{r sctransform, dependson='thresholds', cache=TRUE}
# ------------------------------------------------------------------------------
# - Remove outlier cells
# - Normalize counts using SCTransform
# - If set to 'v2', it causes the model to learn theta and intercept only besides
#   excluding poisson genes from learning and regularization
# - SCTransform() replaces NormalizeData(), ScaleData(), and FindVariableFeatures()
# - https://satijalab.org/seurat/articles/sctransform_v2_vignette
# - https://satijalab.org/seurat/reference/sctransform
# ------------------------------------------------------------------------------

# Remove outlier cells
obj.list <- mclapply(obj.list, function(x) subset(x, subset=keep))

if (length(obj.list) > 1) {

    # Merge all datasets
    obj.merged <- merge(
        x=obj.list[[1]],
        y=obj.list[2:length(obj.list)],
    )

} else {
    
    obj.merged <- obj.list[[1]]

}

# Normalize and find variable features
obj.merged <- NormalizeData(
    obj.merged,
    normalization.method="LogNormalize",
    verbose=FALSE) %>%
    # Retrieve N variable features
    FindVariableFeatures(
        nfeatures=variable.features.n,
        verbose=FALSE) %>%
    ScaleData(verbose=FALSE)

features <- VariableFeatures(obj.merged)

# Reduce dimensions
obj.merged <- RunPCA(
    obj.merged,
    #     assay=selected_assay,
    #     features=features,
    reduction.name=paste0(tolower(selected_assay), '.pca'),
    reduction.key=paste0(tolower(selected_assay), 'pca_'),
    verbose=FALSE,
    npcs=pca_dims) %>%
    RunUMAP(
        #        assay=selected_assay,
       reduction=paste0(tolower(selected_assay), '.pca'),
       reduction.name=paste0(tolower(selected_assay), '.umap'),
       reduction.key=paste0(tolower(selected_assay), 'umap_'),
       verbose=FALSE,
       dims=1:umap_dims)
```


## UMAP plots {.tabset}

Uniform Manifold Approximation and Projection (UMAP) is a manifold learning
technique for dimension reduction that is run on the Principal Component
Analysis (PCA). This is a way to look at sample clustering. The x- and y-axes
do not have units, rather, they represent the dimensions along which the
samples vary the most. The first two dimensions are plotted in the graph below.

Note that these data are not yet clustered; these integrated and non-integrated
versions are for assessing whether or not integration was useful for this
study.

```{r umap, results='asis', fig.width=10, fig.height=8}
DimPlot(
    object=obj.merged,
    reduction=paste0(tolower(selected_assay), '.umap'),
    pt.size=0.1,
    group.by="orig.ident")
```



# Session info

```{r session_info, collapse=FALSE}
sessionInfo()
```

